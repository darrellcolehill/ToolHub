{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darrell/Documents/GitHub/ToolHub/venv_test/lib/python3.12/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:115: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, np.float32(4.7683716e-07), np.float32(6.854534e-07), np.float32(8.34465e-07), np.float32(2.026558e-06), np.float32(3.427267e-06), np.float32(3.9041042e-06), np.float32(4.1127205e-06), np.float32(7.2717667e-06), np.float32(4.3213367e-06), np.float32(2.9802322e-06), np.float32(2.4735928e-06), np.float32(3.2782555e-07), np.float32(1.4901161e-07), np.float32(5.9604645e-07), np.float32(7.4505806e-07), np.float32(8.314848e-06), np.float32(0.00013834238), np.float32(0.0013577044), np.float32(0.0003503561), np.float32(0.0013762116), np.float32(0.00052440166), np.float32(5.5134296e-05), np.float32(0.00022146106), np.float32(9.0807676e-05), np.float32(0.00011354685), np.float32(0.0004531145), np.float32(0.0016038418), np.float32(0.0065260828), np.float32(0.0020931065), np.float32(0.0028995275), np.float32(0.00070136786), np.float32(2.899766e-05), np.float32(1.6063452e-05), np.float32(5.7578087e-05), np.float32(2.9802322e-06), np.float32(3.4570694e-06), np.float32(4.7385693e-06), np.float32(9.4771385e-06), np.float32(0.00036221743), np.float32(0.51937103), np.float32(0.99951947), np.float32(0.9999725), np.float32(0.9999928), np.float32(0.99998915), np.float32(0.99990493), np.float32(0.9994712), np.float32(0.9763416), np.float32(0.21477252), np.float32(0.021579206), np.float32(0.2260187), np.float32(0.6011006), np.float32(0.26416224), np.float32(0.22918248), np.float32(0.23222092), np.float32(0.0008942783), np.float32(9.089708e-06), np.float32(5.8323145e-05), np.float32(0.00026229024), np.float32(0.0021269023), np.float32(0.0016038418), np.float32(0.0017540455), np.float32(0.0053833425), np.float32(0.0020205379), np.float32(0.0001347363), np.float32(5.2154064e-06), np.float32(1.2516975e-06), np.float32(1.66893e-06), np.float32(6.198883e-06), np.float32(2.8312206e-06), np.float32(5.722046e-06), np.float32(7.1525574e-07), np.float32(9.834766e-07), np.float32(2.6226044e-06), np.float32(1.1622906e-06), np.float32(2.2053719e-06), np.float32(3.1292439e-06), np.float32(4.082918e-06), np.float32(7.212162e-06), np.float32(2.0444393e-05), np.float32(1.8835068e-05), np.float32(8.7320805e-06), np.float32(6.28829e-06), np.float32(1.1622906e-06), np.float32(3.2782555e-07), np.float32(4.172325e-07), np.float32(4.7683716e-07), np.float32(1.1920929e-06), np.float32(1.2516975e-06), np.float32(6.854534e-07), np.float32(1.2814999e-06), np.float32(2.8312206e-06), np.float32(7.3313713e-06), np.float32(4.7773123e-05), np.float32(2.7894974e-05), np.float32(5.969405e-05), np.float32(1.5974045e-05), np.float32(1.22487545e-05), np.float32(1.5199184e-05), np.float32(1.7166138e-05), np.float32(2.3841858e-06), np.float32(1.6480684e-05), np.float32(2.2381544e-05), np.float32(2.670288e-05), np.float32(4.2825937e-05), np.float32(4.9948692e-05), np.float32(0.00016155839), np.float32(0.00025048852), np.float32(0.00038829446), np.float32(0.00015074015), np.float32(8.240342e-05), np.float32(2.7656555e-05), np.float32(2.1189451e-05), np.float32(2.9206276e-06), np.float32(1.1622906e-06), np.float32(1.2516975e-06), np.float32(1.2218952e-06), np.float32(5.364418e-07), np.float32(4.4703484e-07), np.float32(5.364418e-07), np.float32(4.7683716e-07), np.float32(6.854534e-07), np.float32(1.1026859e-06), np.float32(2.115965e-06), np.float32(3.784895e-06), np.float32(3.33786e-06), np.float32(2.771616e-06)]\n",
      "Wakeword 'Alexa' detected!\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/dscripka/openWakeWord/blob/main/README.md\n",
    "\n",
    "# Get predictions for individual WAV files (16-bit 16khz PCM)\n",
    "from openwakeword.model import Model\n",
    "\n",
    "model = Model()\n",
    "predictions = model.predict_clip(\"./Darrell - no wake word.wav\")\n",
    "\n",
    "# Extract \"alexa\" scores\n",
    "alexa_scores = [entry.get(\"alexa\", 0) for entry in predictions]\n",
    "\n",
    "# Define a detection threshold\n",
    "threshold = 0.5  # Adjust if needed\n",
    "\n",
    "print(alexa_scores)\n",
    "\n",
    "# Check if any score exceeds the threshold\n",
    "if any(score > threshold for score in alexa_scores):\n",
    "    print(\"Wakeword 'Alexa' detected!\")\n",
    "else:\n",
    "    print(\"Wakeword 'Alexa' not detected.\")\n",
    "\n",
    "\n",
    "# if predictions.get(\"alexa\", 0) > 0.75:  # Adjust threshold as needed\n",
    "#     print(\"Wakeword 'Alexa' detected!\")\n",
    "# else:\n",
    "#     print(\"Wakeword 'Alexa' not detected.\")\n",
    "\n",
    "# Get predictions for a large number of files using multiprocessing\n",
    "# from openwakeword.utils import bulk_predict\n",
    "\n",
    "# bulk_predict(\n",
    "#     file_paths = [\"path/to/wav/file/1\", \"path/to/wav/file/2\"],\n",
    "#     wakeword_models = [\"hey jarvis\"],\n",
    "#     ncpu=2\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
